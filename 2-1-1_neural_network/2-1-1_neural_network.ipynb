{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to do: add xml files to folder \n",
    "# clean up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is this network that we'll be coding up. It has two input neurons, one hidden neuron and one output neuron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2-1-1_nnet.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation and backpropagation graphs are like this: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](backpropagation_2-1-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how similar the computation and backpropagation graphs are to the [1-1-1 neural network](../1-1-1_neural_network/1-1-1_neural_network.ipynb). Really, the only difference is the presence of additional weights and biases at the input layer, which manifests itself as extra boxes down the bottom of the graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to build the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from math import e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.215056266562\n",
      "0.000301170397667\n",
      "0.000137102104799\n",
      "8.80398405885e-05\n",
      "6.46575139803e-05\n",
      "5.1023379279e-05\n",
      "4.21088134553e-05\n",
      "3.58313375948e-05\n",
      "3.11746618516e-05\n",
      "2.7584446658e-05\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.5\n",
    "n_epoch = 10000\n",
    "\n",
    "# create some dummy data \n",
    "X = np.array([[0,0], [1,2], [2,3], [4,4], [5,6], [6,0]])\n",
    "Y = np.array([1,1,0,0,0,1])\n",
    "\n",
    "# init weights and biases \n",
    "w1,w2,w3,b1,b2 = tuple(np.random.random(5))\n",
    "\n",
    "for n in range(n_epoch): \n",
    "    for i in range(X.shape[0]):\n",
    "        a0_0 = X[i,0]\n",
    "        a0_1 = X[i,1]\n",
    "        y = Y[i]\n",
    "\n",
    "        # Define activation function \n",
    "        def sigmoid(x): return e**x / (1 + e**x)\n",
    "\n",
    "        # Forward pass, going up the computation graph \n",
    "        def forward_pass(a0_0, w1, a0_1, w2, b1): \n",
    "            net1 = a0_0 * w1 + a0_1 * w2 + b1\n",
    "            a1 = sigmoid(net1)\n",
    "            net2 = a1 * w3 + b2 \n",
    "            a2 = sigmoid(net2)\n",
    "            Cost = (a2 - y)**2 \n",
    "            return net1, a1, net2, a2, Cost \n",
    "        net1, a1, net2, a2, Cost = forward_pass(a0_0, w1, a0_1, w2, b1)\n",
    "\n",
    "        # Backprop, going down the backprop graph \n",
    "        dCost_dCost = 1 \n",
    "        dCost_da2 = 2 * (a2 - y) * dCost_dCost\n",
    "        dCost_dnet2 = (sigmoid(net2) * (1 - sigmoid(net2))) * dCost_da2\n",
    "        dCost_da1 = w3 * dCost_dnet2\n",
    "        dCost_dw3 = a1 * dCost_dnet2\n",
    "        dCost_db2 = 1  * dCost_dnet2\n",
    "        dCost_dnet1 = (sigmoid(net1) * (1 - sigmoid(net1))) * dCost_da1\n",
    "        dCost_da0_0 = w1   * dCost_dnet1  # useless \n",
    "        dCost_da0_1 = w2   * dCost_dnet1  # useless \n",
    "        dCost_dw1   = a0_0 * dCost_dnet1\n",
    "        dCost_dw2   = a0_1 * dCost_dnet1\n",
    "        dCost_db1   = 1    * dCost_dnet1\n",
    "\n",
    "        # Change the weights \n",
    "        w1   += step_size * -1 * dCost_dw1   \n",
    "        w2   += step_size * -1 * dCost_dw2   \n",
    "        b1   += step_size * -1 * dCost_db1   \n",
    "        w3   += step_size * -1 * dCost_dw3   \n",
    "        b2   += step_size * -1 * dCost_db2  \n",
    "\n",
    "    if n % 1000 == 0 : \n",
    "        #print(np.array([w1,w2,b1,w3,b2]))\n",
    "        print(Cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.99678222212736689,\n",
       " 0.98791285318365962,\n",
       " 0.010530133392770348,\n",
       " 0.0031717888994224541,\n",
       " 0.0031478722889073073,\n",
       " 0.99502744887332983]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [forward_pass(X[i,0], w1, X[i,1], w2, b1)[3] for i in range(X.shape[0])]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
